import { useEffect, useRef, useState } from 'react';
import { getRecordingDurationSync, getPlaybackRate } from '../../components/SidebarSettings';
import { analyzeTitleForStep2, submitChildrenVoice } from '../../lib/level1-api';
import VoiceRecorder from '../../components/VoiceRecorder';
import type { Level1TitleAnalysisResponse, Level1ChildrenVoiceResponse } from '../../types';
import { useSelector } from 'react-redux';
import type { RootState } from '../../store/store';
import { useStepContext } from '../../contexts/StepContext';
import { useAudioPlaybackRate } from '../../hooks/useAudioPlaybackRate';
import { getStoryById } from '../../lib/supabase';
import { getStoryImageUrl, getAssetUrl } from '../../lib/image-utils';

export default function Step2() {
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const [introPlayed, setIntroPlayed] = useState(false); // Intro audio finished
  const [started, setStarted] = useState(false); // User clicked "BaÅŸla"
  const [mascotState, setMascotState] = useState<'idle' | 'speaking' | 'listening'>('idle');
  const [analysisText, setAnalysisText] = useState('');
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [childrenVoiceResponse, setChildrenVoiceResponse] = useState('');
  const [isProcessingVoice, setIsProcessingVoice] = useState(false);
  const [resumeUrl, setResumeUrl] = useState('');
  const [audioProgress, setAudioProgress] = useState(0);
  const [audioDuration, setAudioDuration] = useState(0);
  const [showIntroText, setShowIntroText] = useState(true);
  const [story, setStory] = useState<{ id: number; title: string; description: string; image: string } | null>(null);
  const currentStudent = useSelector((state: RootState) => state.user.student);
  const { sessionId, onStepCompleted, storyId, setFooterVisible } = useStepContext();
  
  // Apply playback rate to audio element
  useAudioPlaybackRate(audioRef);

  // Correct audio path using getAssetUrl for GitHub Pages compatibility
  const introAudio = getAssetUrl('audios/level1/seviye-1-adim-2-fable.mp3');

  // Load story data from Supabase
  useEffect(() => {
    const loadStory = async () => {
      try {
        const { data, error } = await getStoryById(storyId);
        if (error || !data) {
          // Fallback to default story - use local image path
          setStory({
            id: storyId,
            title: `Oturum ${storyId}`,
            description: '',
            image: `/images/story${storyId}.png`,
          });
        } else {
          // Use image from Supabase if available, otherwise use local path
          const imagePath = data.image || `/images/story${storyId}.png`;
          setStory({
            id: data.id,
            title: data.title,
            description: data.description || '',
            image: imagePath,
          });
        }
      } catch (e) {
        // Fallback to default story - use local image path
        setStory({
          id: storyId,
          title: `Oturum ${storyId}`,
          description: '',
          image: `/images/story${storyId}.png`,
        });
      }
    };
    loadStory();
  }, [storyId]);

  // Play intro audio when component mounts (before showing BaÅŸla button)
  useEffect(() => {
    if (introPlayed) return; // Already played
    
    const playIntroAudio = async () => {
      if (!audioRef.current) {
        // If no audio element, just mark as played
        setIntroPlayed(true);
        return;
      }
      
      try {
        audioRef.current.src = introAudio;
        audioRef.current.playbackRate = getPlaybackRate();
        setMascotState('speaking');
        
        const handleEnded = () => {
          setMascotState('idle');
          setIntroPlayed(true);
          audioRef.current?.removeEventListener('ended', handleEnded);
        };
        
        audioRef.current.addEventListener('ended', handleEnded);
        await audioRef.current.play();
      } catch (err) {
        console.error('Intro audio play error:', err);
        // If audio fails, still show the button
        setIntroPlayed(true);
      }
    };
    
    // Small delay to ensure audio element is ready
    const timer = setTimeout(playIntroAudio, 300);
    
    return () => {
      clearTimeout(timer);
    };
  }, [introAudio, introPlayed]);

  // When user clicks "BaÅŸla", start the analysis
  useEffect(() => {
    if (!started || analysisText) return;
    
    // Start title analysis
    handleTitleAnalysis();
  }, [started, analysisText]);

  useEffect(() => {
    const stopAll = () => {
      if (audioRef.current) {
        try {
          audioRef.current.pause();
        } catch {}
      }
    };
    window.addEventListener('STOP_ALL_AUDIO' as any, stopAll);
    return () => window.removeEventListener('STOP_ALL_AUDIO' as any, stopAll);
  }, []);

  const playAudioFromBase64 = async (base64: string) => {
    console.log('ğŸ”Š playAudioFromBase64 called, base64 length:', base64?.length || 0);
    if (!audioRef.current || !base64) {
      console.warn('âš ï¸ Audio ref or base64 missing');
      return;
    }
    const tryMime = async (mime: string) => {
      const src = base64.trim().startsWith('data:') ? base64.trim() : `data:${mime};base64,${base64.trim()}`;
      console.log('ğŸµ Playing audio with mime:', mime);
      audioRef.current!.src = src;
      // Apply playback rate
      audioRef.current!.playbackRate = getPlaybackRate();
      setMascotState('speaking');

      // Reset progress
      setAudioProgress(0);
      setAudioDuration(0);

      // Update duration when metadata is loaded
      const onLoadedMetadata = () => {
        setAudioDuration(audioRef.current?.duration || 0);
      };

      // Update progress during playback
      const onTimeUpdate = () => {
        setAudioProgress(audioRef.current?.currentTime || 0);
      };

      // Clean up and set to listening when done
      const onEnded = () => {
        setMascotState('listening');
        setAudioProgress(0);
        setAudioDuration(0);
        audioRef.current?.removeEventListener('loadedmetadata', onLoadedMetadata);
        audioRef.current?.removeEventListener('timeupdate', onTimeUpdate);
        audioRef.current?.removeEventListener('ended', onEnded);
      };

      audioRef.current?.addEventListener('loadedmetadata', onLoadedMetadata);
      audioRef.current?.addEventListener('timeupdate', onTimeUpdate);
      audioRef.current?.addEventListener('ended', onEnded);

      await audioRef.current!.play();
    };
    try {
      await tryMime('audio/mpeg');
    } catch {
      try {
        await tryMime('audio/webm;codecs=opus');
      } catch (e) {
        setMascotState('listening');
        setAudioProgress(0);
        setAudioDuration(0);
        throw e;
      }
    }
  };

  const handleTitleAnalysis = async () => {
    setIsAnalyzing(true);
    try {
      const response: Level1TitleAnalysisResponse = await analyzeTitleForStep2({
        stepNum: 2,
        // âš ï¸ n8n workflow "userId" alanÄ±nÄ± bekliyor
        // DeÄŸer olarak sessionId gÃ¶nderiliyor (her session iÃ§in unique)
        // Bu sayede aynÄ± kullanÄ±cÄ±nÄ±n farklÄ± hikayeleri karÄ±ÅŸmaz
        userId: sessionId || `anon-${Date.now()}`,
      });

      const text =
        response.titleExplanation ||
        response.imageExplanation ||
        response.message ||
        response.text ||
        response.response ||
        response.textAudio ||
        '';

      setAnalysisText(text);
      setShowIntroText(false);
      setResumeUrl(response.resumeUrl);

      console.log('ğŸ“¥ API response received:', {
        hasAudioBase64: !!response.audioBase64,
        audioBase64Length: response.audioBase64?.length || 0,
        text: text?.substring(0, 100) + '...',
      });

      if (response.audioBase64) {
        try {
          console.log('ğŸ”Š Attempting to play API response audio...');
          await playAudioFromBase64(response.audioBase64);
          console.log('âœ… Audio playback started');
        } catch (e) {
          console.error('âŒ Audio playback error:', e);
          setMascotState('listening');
        }
      } else {
        console.log('âš ï¸ No audioBase64 in response');
        setMascotState('listening');
      }
    } catch (e) {
      setAnalysisText('');
      setMascotState('listening');
    } finally {
      setIsAnalyzing(false);
    }
  };

  const handleVoiceSubmit = async (audioBlob: Blob) => {
    if (!story) return;
    setIsProcessingVoice(true);
    try {
      const response: Level1ChildrenVoiceResponse = await submitChildrenVoice(
        audioBlob,
        resumeUrl,
        story.title,
        2,
        'baslik_tahmini'
      );

      const responseText =
        response.respodKidVoice ||
        response.message ||
        response.text ||
        response.response ||
        response.textAudio ||
        '';

      setChildrenVoiceResponse(responseText);

      console.log('ğŸ“¥ Voice response received:', {
        hasAudioBase64: !!response.audioBase64,
        audioBase64Length: response.audioBase64?.length || 0,
      });

      if (response.audioBase64) {
        try {
          console.log('ğŸ”Š Attempting to play voice response audio...');
          await playAudioFromBase64(response.audioBase64);
          console.log('âœ… Voice response audio started');
        } catch (e) {
          console.error('âŒ Voice response audio error:', e);
          setMascotState('listening');
        }
      } else {
        console.log('âš ï¸ No audioBase64 in voice response');
        setMascotState('listening');
      }
    } catch (e) {
      console.error('âŒ Voice submit error:', e);
      setChildrenVoiceResponse('');
      setMascotState('listening');
    } finally {
      setIsProcessingVoice(false);
    }
  };

  // Mark step as completed when both analysis and voice response are done
  useEffect(() => {
    if (analysisText && childrenVoiceResponse && onStepCompleted) {
      onStepCompleted({
        analysisText,
        childrenVoiceResponse,
        resumeUrl
      });
    }
  }, [analysisText, childrenVoiceResponse, onStepCompleted, resumeUrl]);

  return (
    <div className="flex-1 flex flex-col items-center justify-center relative mt-0">
      <audio ref={audioRef} preload="auto" />

      {!started ? (
        <div className="flex-1 flex flex-col items-center justify-center">
          <div className="bg-white rounded-xl shadow-lg border border-purple-200 p-6 max-w-2xl text-center">
            <h2 className="text-2xl font-semibold text-purple-800 mb-2">
              2. AdÄ±m: Metnin baÅŸlÄ±ÄŸÄ±nÄ± inceleme ve tahminde bulunma
            </h2>
            <p className="text-gray-700">
              Åimdi bu seviyenin ikinci basamaÄŸÄ±nda metnin baÅŸlÄ±ÄŸÄ±nÄ± inceleyeceÄŸiz ve baÅŸlÄ±ktan yola Ã§Ä±karak metnin iÃ§eriÄŸine yÃ¶nelik tahminde bulunacaÄŸÄ±z.
            </p>
            
            {/* Show speaking indicator while intro audio is playing */}
            {!introPlayed && mascotState === 'speaking' && (
              <div className="mt-4 flex items-center justify-center gap-2 text-purple-600">
                <div className="animate-pulse">ğŸ”Š</div>
                <span className="font-medium">DOST aÃ§Ä±klÄ±yor...</span>
              </div>
            )}
          </div>
          
          {/* Show BaÅŸla button only after intro audio finishes */}
          {introPlayed && (
            <button
              onClick={() => { setStarted(true); setFooterVisible(true); }}
              className="mt-6 bg-purple-600 text-white px-8 py-4 rounded-full shadow-lg hover:bg-purple-700 transition text-xl font-bold"
            >
              BaÅŸla
            </button>
          )}
        </div>
      ) : (
        <div className="w-full max-w-6xl mx-auto px-4">
          {story && (
            <div className="flex flex-col lg:flex-row items-center gap-8">
              <div className="lg:w-1/2 w-full">
                <div className="relative">
                  <img src={getStoryImageUrl(story.image)} alt={story.title} className="w-full max-w-md mx-auto rounded-xl shadow-lg" />
                </div>
                <h2 className="mt-4 text-2xl font-bold text-purple-800 text-center">{story.title}</h2>
              </div>

            <div className="lg:w-1/2 w-full">
              <div className="bg-white rounded-xl shadow-lg p-6">
                {showIntroText && !analysisText && !isAnalyzing && (
                  <div className="p-4 bg-yellow-50 rounded-lg border border-yellow-200 mb-6">
                    <h3 className="font-bold text-yellow-800 mb-2">ğŸ¤– DOST'un Notu:</h3>
                    <p className="text-yellow-700">Åimdi bu seviyenin ikinci basamaÄŸÄ±nda metnin baÅŸlÄ±ÄŸÄ±nÄ± inceleyeceÄŸiz ve baÅŸlÄ±ktan yola Ã§Ä±karak metnin iÃ§eriÄŸine yÃ¶nelik tahminde bulunacaÄŸÄ±z.</p>
                  </div>
                )}

                {isAnalyzing && !analysisText && (
                  <div className="p-4 bg-blue-50 rounded-lg border border-blue-200 mb-6">
                    <p className="text-blue-700 font-medium">DOST baÅŸlÄ±ÄŸÄ± analiz ediyor...</p>
                  </div>
                )}

                {mascotState === 'speaking' && audioDuration > 0 && (
                  <div className="mb-4 space-y-1">
                    <div className="w-full bg-gray-200 rounded-full h-1">
                      <div
                        className="bg-blue-500 h-1 rounded-full transition-all duration-100"
                        style={{ width: `${(audioProgress / audioDuration) * 100}%` }}
                      />
                    </div>
                    <p className="text-xs text-gray-500 text-center">
                      {Math.floor(audioProgress)}s / {Math.floor(audioDuration)}s
                    </p>
                  </div>
                )}

                {analysisText && !childrenVoiceResponse && (
                  <div className="p-4 bg-blue-50 rounded-lg border border-blue-200 mb-6">
                    <h3 className="font-bold text-blue-800 mb-2">ğŸ¤– DOST'un BaÅŸlÄ±k Analizi:</h3>
                    <p className="text-blue-700">{analysisText}</p>
                  </div>
                )}

                {/* Only show microphone after audio is finished (mascotState === 'listening') */}
                {analysisText && !childrenVoiceResponse && mascotState === 'listening' && (
                  <div className="text-center">
                    <p className="mb-4 text-xl font-bold text-green-700 animate-pulse">Hadi sÄ±ra sende! Mikrofona konuÅŸ</p>
                    <VoiceRecorder
                      recordingDurationMs={getRecordingDurationSync()}
                      autoSubmit={true}
                      onSave={handleVoiceSubmit}
                      onPlayStart={() => {
                        try {
                          window.dispatchEvent(new Event('STOP_ALL_AUDIO' as any));
                        } catch {}
                      }}
                      storyId={storyId}
                      level={1}
                      step={2}
                      disabled={isProcessingVoice}
                    />
                    {isProcessingVoice && (
                      <p className="mt-4 text-blue-600 font-medium">DOST senin sÃ¶zlerini deÄŸerlendiriyor...</p>
                    )}
                  </div>
                )}

                {childrenVoiceResponse && (
                  <div className="mt-6 p-4 bg-green-50 rounded-lg border border-green-200">
                    <h3 className="font-bold text-green-800 mb-2">ğŸ—£ï¸ DOST'un Yorumu:</h3>
                    <p className="text-green-700 text-lg">{childrenVoiceResponse}</p>
                  </div>
                )}
              </div>
            </div>
            </div>
          )}
        </div>
      )}
    </div>
  );
}
